nohup: ignoring input
Start training.
--------------- The 1-th fold as the validation set... ---------------
Cascade_Binary: Preprocessing dataset...
Data length:  11314
Epoch id: 1, Training steps: 250, Loss: 2.780578
Epoch id: 1, Training steps: 500, Loss: 2.256101
Epoch id: 1, Training steps: 750, Loss: 2.054725
Epoch id: 1, Training steps: 1000, Loss: 1.855071
Epoch id: 1, Training steps: 1250, Loss: 1.581335
Epoch id: 2, Training steps: 250, Loss: 2.182854
Epoch id: 2, Training steps: 500, Loss: 1.182121
Epoch id: 2, Training steps: 750, Loss: 1.111441
Epoch id: 2, Training steps: 1000, Loss: 1.055108
Epoch id: 2, Training steps: 1250, Loss: 1.016640
Epoch id: 3, Training steps: 250, Loss: 1.613048
Epoch id: 3, Training steps: 500, Loss: 0.939475
Epoch id: 3, Training steps: 750, Loss: 0.940012
Epoch id: 3, Training steps: 1000, Loss: 0.918759
Epoch id: 3, Training steps: 1250, Loss: 0.907066
Epoch id: 4, Training steps: 250, Loss: 1.472371
Epoch id: 4, Training steps: 500, Loss: 0.871792
Epoch id: 4, Training steps: 750, Loss: 0.864764
Epoch id: 4, Training steps: 1000, Loss: 0.861159
Epoch id: 4, Training steps: 1250, Loss: 0.865173
Epoch id: 5, Training steps: 250, Loss: 1.404906
Epoch id: 5, Training steps: 500, Loss: 0.847771
Epoch id: 5, Training steps: 750, Loss: 0.841754
Epoch id: 5, Training steps: 1000, Loss: 0.833063
Epoch id: 5, Training steps: 1250, Loss: 0.847317
Epoch id: 6, Training steps: 250, Loss: 1.380581
Epoch id: 6, Training steps: 500, Loss: 0.834085
Epoch id: 6, Training steps: 750, Loss: 0.813346
Epoch id: 6, Training steps: 1000, Loss: 0.821410
Epoch id: 6, Training steps: 1250, Loss: 0.823902
Epoch id: 7, Training steps: 250, Loss: 1.335641
Epoch id: 7, Training steps: 500, Loss: 0.806905
Epoch id: 7, Training steps: 750, Loss: 0.801664
Epoch id: 7, Training steps: 1000, Loss: 0.818502
Epoch id: 7, Training steps: 1250, Loss: 0.818688
Epoch id: 8, Training steps: 250, Loss: 1.320532
Epoch id: 8, Training steps: 500, Loss: 0.802534
Epoch id: 8, Training steps: 750, Loss: 0.802428
Epoch id: 8, Training steps: 1000, Loss: 0.800162
Epoch id: 8, Training steps: 1250, Loss: 0.794304
Epoch id: 9, Training steps: 250, Loss: 1.311665
Epoch id: 9, Training steps: 500, Loss: 0.788461
Epoch id: 9, Training steps: 750, Loss: 0.786202
Epoch id: 9, Training steps: 1000, Loss: 0.777510
Epoch id: 9, Training steps: 1250, Loss: 0.776147
Epoch id: 10, Training steps: 250, Loss: 1.281320
Epoch id: 10, Training steps: 500, Loss: 0.767613
Epoch id: 10, Training steps: 750, Loss: 0.745634
Epoch id: 10, Training steps: 1000, Loss: 0.763330
Epoch id: 10, Training steps: 1250, Loss: 0.750268
Epoch id: 11, Training steps: 250, Loss: 1.218593
Epoch id: 11, Training steps: 500, Loss: 0.720699
Epoch id: 11, Training steps: 750, Loss: 0.724499
Epoch id: 11, Training steps: 1000, Loss: 0.712101
Epoch id: 11, Training steps: 1250, Loss: 0.729055
Epoch id: 12, Training steps: 250, Loss: 1.187801
Epoch id: 12, Training steps: 500, Loss: 0.695569
Epoch id: 12, Training steps: 750, Loss: 0.685935
Epoch id: 12, Training steps: 1000, Loss: 0.689853
Epoch id: 12, Training steps: 1250, Loss: 0.695624
Epoch id: 13, Training steps: 250, Loss: 1.131243
Epoch id: 13, Training steps: 500, Loss: 0.677661
Epoch id: 13, Training steps: 750, Loss: 0.662222
Epoch id: 13, Training steps: 1000, Loss: 0.669725
Epoch id: 13, Training steps: 1250, Loss: 0.688738
Epoch id: 14, Training steps: 250, Loss: 1.102011
Epoch id: 14, Training steps: 500, Loss: 0.648430
Epoch id: 14, Training steps: 750, Loss: 0.654320
Epoch id: 14, Training steps: 1000, Loss: 0.658930
Epoch id: 14, Training steps: 1250, Loss: 0.657278
Epoch id: 15, Training steps: 250, Loss: 1.078382
Epoch id: 15, Training steps: 500, Loss: 0.634461
Epoch id: 15, Training steps: 750, Loss: 0.633065
Epoch id: 15, Training steps: 1000, Loss: 0.633332
Epoch id: 15, Training steps: 1250, Loss: 0.658906
Epoch id: 16, Training steps: 250, Loss: 1.061093
Epoch id: 16, Training steps: 500, Loss: 0.639825
Epoch id: 16, Training steps: 750, Loss: 0.625201
Epoch id: 16, Training steps: 1000, Loss: 0.618165
Epoch id: 16, Training steps: 1250, Loss: 0.630332
Epoch id: 17, Training steps: 250, Loss: 1.040365
Epoch id: 17, Training steps: 500, Loss: 0.627221
Epoch id: 17, Training steps: 750, Loss: 0.636506
Epoch id: 17, Training steps: 1000, Loss: 0.625237
Epoch id: 17, Training steps: 1250, Loss: 0.616824
Epoch id: 18, Training steps: 250, Loss: 1.019944
Epoch id: 18, Training steps: 500, Loss: 0.626819
Epoch id: 18, Training steps: 750, Loss: 0.618864
Epoch id: 18, Training steps: 1000, Loss: 0.611585
Epoch id: 18, Training steps: 1250, Loss: 0.607104
Epoch id: 19, Training steps: 250, Loss: 1.017567
Epoch id: 19, Training steps: 500, Loss: 0.607755
Epoch id: 19, Training steps: 750, Loss: 0.621651
Epoch id: 19, Training steps: 1000, Loss: 0.618856
Epoch id: 19, Training steps: 1250, Loss: 0.604349
Epoch id: 20, Training steps: 250, Loss: 1.007612
Epoch id: 20, Training steps: 500, Loss: 0.612328
Epoch id: 20, Training steps: 750, Loss: 0.613837
Epoch id: 20, Training steps: 1000, Loss: 0.620428
Epoch id: 20, Training steps: 1250, Loss: 0.606635
Event: total_right, total_predict, predict_right: 5002, 32177, 1477
Event: precision, recall, and f1: 0.046, 0.295, 0.079
Role: total_right, total_predict, predict_right: 5354, 398436, 53
Role: precision, recall, and f1: 0.000, 0.010, 0.000
Saving middle model...
Epoch id: 21, Training steps: 250, Loss: 1.003903
Epoch id: 21, Training steps: 500, Loss: 0.626343
Epoch id: 21, Training steps: 750, Loss: 0.600215
Epoch id: 21, Training steps: 1000, Loss: 0.596253
Epoch id: 21, Training steps: 1250, Loss: 0.595603
Epoch id: 22, Training steps: 250, Loss: 0.990626
Epoch id: 22, Training steps: 500, Loss: 0.586904
Epoch id: 22, Training steps: 750, Loss: 0.602346
Epoch id: 22, Training steps: 1000, Loss: 0.592747
Epoch id: 22, Training steps: 1250, Loss: 0.600275
Epoch id: 23, Training steps: 250, Loss: 0.970561
Epoch id: 23, Training steps: 500, Loss: 0.599627
Epoch id: 23, Training steps: 750, Loss: 0.595974
Epoch id: 23, Training steps: 1000, Loss: 0.593382
Epoch id: 23, Training steps: 1250, Loss: 0.582826
Epoch id: 24, Training steps: 250, Loss: 0.989816
Epoch id: 24, Training steps: 500, Loss: 0.583882
Epoch id: 24, Training steps: 750, Loss: 0.585418
Epoch id: 24, Training steps: 1000, Loss: 0.586936
Epoch id: 24, Training steps: 1250, Loss: 0.586591
Epoch id: 25, Training steps: 250, Loss: 0.961193
Epoch id: 25, Training steps: 500, Loss: 0.591803
Epoch id: 25, Training steps: 750, Loss: 0.580945
Epoch id: 25, Training steps: 1000, Loss: 0.568615
Epoch id: 25, Training steps: 1250, Loss: 0.598431
Epoch id: 26, Training steps: 250, Loss: 0.955886
Epoch id: 26, Training steps: 500, Loss: 0.569978
Epoch id: 26, Training steps: 750, Loss: 0.582867
Epoch id: 26, Training steps: 1000, Loss: 0.579661
Epoch id: 26, Training steps: 1250, Loss: 0.586306
Epoch id: 27, Training steps: 250, Loss: 0.976139
Epoch id: 27, Training steps: 500, Loss: 0.585890
Epoch id: 27, Training steps: 750, Loss: 0.581562
Epoch id: 27, Training steps: 1000, Loss: 0.579655
Epoch id: 27, Training steps: 1250, Loss: 0.572415
Epoch id: 28, Training steps: 250, Loss: 0.944814
Epoch id: 28, Training steps: 500, Loss: 0.569024
Epoch id: 28, Training steps: 750, Loss: 0.569270
Epoch id: 28, Training steps: 1000, Loss: 0.579336
Epoch id: 28, Training steps: 1250, Loss: 0.563550
Epoch id: 29, Training steps: 250, Loss: 0.952611
Epoch id: 29, Training steps: 500, Loss: 0.559859
Epoch id: 29, Training steps: 750, Loss: 0.574203
Epoch id: 29, Training steps: 1000, Loss: 0.582103
Epoch id: 29, Training steps: 1250, Loss: 0.574791
Epoch id: 30, Training steps: 250, Loss: 0.937910
Epoch id: 30, Training steps: 500, Loss: 0.563307
Epoch id: 30, Training steps: 750, Loss: 0.571720
Epoch id: 30, Training steps: 1000, Loss: 0.556271
Epoch id: 30, Training steps: 1250, Loss: 0.560711
Epoch id: 31, Training steps: 250, Loss: 0.951137
Epoch id: 31, Training steps: 500, Loss: 0.552196
Epoch id: 31, Training steps: 750, Loss: 0.568414
Epoch id: 31, Training steps: 1000, Loss: 0.552058
Epoch id: 31, Training steps: 1250, Loss: 0.570484
Epoch id: 32, Training steps: 250, Loss: 0.917751
Epoch id: 32, Training steps: 500, Loss: 0.579209
Epoch id: 32, Training steps: 750, Loss: 0.555050
Epoch id: 32, Training steps: 1000, Loss: 0.572681
Epoch id: 32, Training steps: 1250, Loss: 0.565564
Epoch id: 33, Training steps: 250, Loss: 0.936628
Epoch id: 33, Training steps: 500, Loss: 0.570916
Epoch id: 33, Training steps: 750, Loss: 0.559578
Epoch id: 33, Training steps: 1000, Loss: 0.555062
Epoch id: 33, Training steps: 1250, Loss: 0.562537
Epoch id: 34, Training steps: 250, Loss: 0.926373
Epoch id: 34, Training steps: 500, Loss: 0.550036
Epoch id: 34, Training steps: 750, Loss: 0.551473
Epoch id: 34, Training steps: 1000, Loss: 0.559087
Epoch id: 34, Training steps: 1250, Loss: 0.566083
Epoch id: 35, Training steps: 250, Loss: 0.921524
Epoch id: 35, Training steps: 500, Loss: 0.568699
Epoch id: 35, Training steps: 750, Loss: 0.552130
Epoch id: 35, Training steps: 1000, Loss: 0.540380
Epoch id: 35, Training steps: 1250, Loss: 0.550356
Epoch id: 36, Training steps: 250, Loss: 0.919104
Epoch id: 36, Training steps: 500, Loss: 0.554792
Epoch id: 36, Training steps: 750, Loss: 0.541665
Epoch id: 36, Training steps: 1000, Loss: 0.555775
Epoch id: 36, Training steps: 1250, Loss: 0.564248
Epoch id: 37, Training steps: 250, Loss: 0.918977
Epoch id: 37, Training steps: 500, Loss: 0.555747
Epoch id: 37, Training steps: 750, Loss: 0.535830
Epoch id: 37, Training steps: 1000, Loss: 0.551906
Epoch id: 37, Training steps: 1250, Loss: 0.561657
Epoch id: 38, Training steps: 250, Loss: 0.909211
Epoch id: 38, Training steps: 500, Loss: 0.562683
Epoch id: 38, Training steps: 750, Loss: 0.539483
Epoch id: 38, Training steps: 1000, Loss: 0.549440
Epoch id: 38, Training steps: 1250, Loss: 0.562822
Epoch id: 39, Training steps: 250, Loss: 0.901842
Epoch id: 39, Training steps: 500, Loss: 0.544530
Epoch id: 39, Training steps: 750, Loss: 0.554973
Epoch id: 39, Training steps: 1000, Loss: 0.559121
Epoch id: 39, Training steps: 1250, Loss: 0.539623
Epoch id: 40, Training steps: 250, Loss: 0.909344
Epoch id: 40, Training steps: 500, Loss: 0.533947
Epoch id: 40, Training steps: 750, Loss: 0.554318
Epoch id: 40, Training steps: 1000, Loss: 0.550631
Epoch id: 40, Training steps: 1250, Loss: 0.545588
Event: total_right, total_predict, predict_right: 5002, 36138, 1714
Event: precision, recall, and f1: 0.047, 0.343, 0.083
Role: total_right, total_predict, predict_right: 5354, 660591, 56
Role: precision, recall, and f1: 0.000, 0.010, 0.000
Epoch id: 41, Training steps: 250, Loss: 0.903937
Epoch id: 41, Training steps: 500, Loss: 0.542307
Epoch id: 41, Training steps: 750, Loss: 0.543328
Epoch id: 41, Training steps: 1000, Loss: 0.541764
Epoch id: 41, Training steps: 1250, Loss: 0.553887
Epoch id: 42, Training steps: 250, Loss: 0.913568
Epoch id: 42, Training steps: 500, Loss: 0.546141
Epoch id: 42, Training steps: 750, Loss: 0.539070
Epoch id: 42, Training steps: 1000, Loss: 0.540221
Epoch id: 42, Training steps: 1250, Loss: 0.541020
Epoch id: 43, Training steps: 250, Loss: 0.910900
Epoch id: 43, Training steps: 500, Loss: 0.534779
Epoch id: 43, Training steps: 750, Loss: 0.541129
Epoch id: 43, Training steps: 1000, Loss: 0.546444
Epoch id: 43, Training steps: 1250, Loss: 0.561436
Epoch id: 44, Training steps: 250, Loss: 0.915137
Epoch id: 44, Training steps: 500, Loss: 0.546111
Epoch id: 44, Training steps: 750, Loss: 0.537212
Epoch id: 44, Training steps: 1000, Loss: 0.540644
Epoch id: 44, Training steps: 1250, Loss: 0.540754
Epoch id: 45, Training steps: 250, Loss: 0.907250
Epoch id: 45, Training steps: 500, Loss: 0.540591
Epoch id: 45, Training steps: 750, Loss: 0.532889
Epoch id: 45, Training steps: 1000, Loss: 0.555171
Epoch id: 45, Training steps: 1250, Loss: 0.534423
Epoch id: 46, Training steps: 250, Loss: 0.906115
Epoch id: 46, Training steps: 500, Loss: 0.525895
Epoch id: 46, Training steps: 750, Loss: 0.526980
Epoch id: 46, Training steps: 1000, Loss: 0.545331
Epoch id: 46, Training steps: 1250, Loss: 0.537416
Epoch id: 47, Training steps: 250, Loss: 0.912784
Epoch id: 47, Training steps: 500, Loss: 0.540364
Epoch id: 47, Training steps: 750, Loss: 0.534683
Epoch id: 47, Training steps: 1000, Loss: 0.544172
Epoch id: 47, Training steps: 1250, Loss: 0.533088
Epoch id: 48, Training steps: 250, Loss: 0.896477
Epoch id: 48, Training steps: 500, Loss: 0.529373
Epoch id: 48, Training steps: 750, Loss: 0.557039
Epoch id: 48, Training steps: 1000, Loss: 0.527834
Epoch id: 48, Training steps: 1250, Loss: 0.537521
Epoch id: 49, Training steps: 250, Loss: 0.893065
Epoch id: 49, Training steps: 500, Loss: 0.542124
Epoch id: 49, Training steps: 750, Loss: 0.530839
Epoch id: 49, Training steps: 1000, Loss: 0.531024
Epoch id: 49, Training steps: 1250, Loss: 0.534983
Epoch id: 50, Training steps: 250, Loss: 0.882291
Epoch id: 50, Training steps: 500, Loss: 0.514324
Epoch id: 50, Training steps: 750, Loss: 0.531763
Epoch id: 50, Training steps: 1000, Loss: 0.546190
Epoch id: 50, Training steps: 1250, Loss: 0.536793
Epoch id: 51, Training steps: 250, Loss: 0.894615
Epoch id: 51, Training steps: 500, Loss: 0.525286
Epoch id: 51, Training steps: 750, Loss: 0.545187
Epoch id: 51, Training steps: 1000, Loss: 0.534936
Epoch id: 51, Training steps: 1250, Loss: 0.534893
Epoch id: 52, Training steps: 250, Loss: 0.869545
Epoch id: 52, Training steps: 500, Loss: 0.527423
Epoch id: 52, Training steps: 750, Loss: 0.543497
Epoch id: 52, Training steps: 1000, Loss: 0.527568
Epoch id: 52, Training steps: 1250, Loss: 0.535023
Epoch id: 53, Training steps: 250, Loss: 0.902163
Epoch id: 53, Training steps: 500, Loss: 0.543285
Epoch id: 53, Training steps: 750, Loss: 0.527191
Epoch id: 53, Training steps: 1000, Loss: 0.520493
Epoch id: 53, Training steps: 1250, Loss: 0.535303
Epoch id: 54, Training steps: 250, Loss: 0.885786
Epoch id: 54, Training steps: 500, Loss: 0.531894
Epoch id: 54, Training steps: 750, Loss: 0.525099
Epoch id: 54, Training steps: 1000, Loss: 0.533699
Epoch id: 54, Training steps: 1250, Loss: 0.526203
Epoch id: 55, Training steps: 250, Loss: 0.872059
Epoch id: 55, Training steps: 500, Loss: 0.546706
Epoch id: 55, Training steps: 750, Loss: 0.534067
Epoch id: 55, Training steps: 1000, Loss: 0.529730
Epoch id: 55, Training steps: 1250, Loss: 0.536489
Epoch id: 56, Training steps: 250, Loss: 0.873348
Epoch id: 56, Training steps: 500, Loss: 0.543452
Epoch id: 56, Training steps: 750, Loss: 0.518993
Epoch id: 56, Training steps: 1000, Loss: 0.533345
Epoch id: 56, Training steps: 1250, Loss: 0.536428
Epoch id: 57, Training steps: 250, Loss: 0.875041
Epoch id: 57, Training steps: 500, Loss: 0.527521
Epoch id: 57, Training steps: 750, Loss: 0.545301
Epoch id: 57, Training steps: 1000, Loss: 0.524916
Epoch id: 57, Training steps: 1250, Loss: 0.512720
Epoch id: 58, Training steps: 250, Loss: 0.897188
Epoch id: 58, Training steps: 500, Loss: 0.527753
Epoch id: 58, Training steps: 750, Loss: 0.519329
Epoch id: 58, Training steps: 1000, Loss: 0.526499
Epoch id: 58, Training steps: 1250, Loss: 0.528429
Epoch id: 59, Training steps: 250, Loss: 0.889498
Epoch id: 59, Training steps: 500, Loss: 0.527871
Epoch id: 59, Training steps: 750, Loss: 0.519479
Epoch id: 59, Training steps: 1000, Loss: 0.522426
Epoch id: 59, Training steps: 1250, Loss: 0.532377
Epoch id: 60, Training steps: 250, Loss: 0.867492
Epoch id: 60, Training steps: 500, Loss: 0.525787
Epoch id: 60, Training steps: 750, Loss: 0.523673
Epoch id: 60, Training steps: 1000, Loss: 0.528668
Epoch id: 60, Training steps: 1250, Loss: 0.531953
Event: total_right, total_predict, predict_right: 5002, 57451, 2201
Event: precision, recall, and f1: 0.038, 0.440, 0.070
Role: total_right, total_predict, predict_right: 5354, 1349758, 43
Role: precision, recall, and f1: 0.000, 0.008, 0.000
Epoch id: 61, Training steps: 250, Loss: 0.874455
Epoch id: 61, Training steps: 500, Loss: 0.525731
Epoch id: 61, Training steps: 750, Loss: 0.526115
Epoch id: 61, Training steps: 1000, Loss: 0.526630
Epoch id: 61, Training steps: 1250, Loss: 0.532832
Epoch id: 62, Training steps: 250, Loss: 0.877298
Epoch id: 62, Training steps: 500, Loss: 0.516118
Epoch id: 62, Training steps: 750, Loss: 0.516940
Epoch id: 62, Training steps: 1000, Loss: 0.531931
Epoch id: 62, Training steps: 1250, Loss: 0.516501
Epoch id: 63, Training steps: 250, Loss: 0.871861
Epoch id: 63, Training steps: 500, Loss: 0.527995
Epoch id: 63, Training steps: 750, Loss: 0.522966
Epoch id: 63, Training steps: 1000, Loss: 0.525113
Epoch id: 63, Training steps: 1250, Loss: 0.535733
Epoch id: 64, Training steps: 250, Loss: 0.875938
Epoch id: 64, Training steps: 500, Loss: 0.524027
Epoch id: 64, Training steps: 750, Loss: 0.528556
Epoch id: 64, Training steps: 1000, Loss: 0.533137
Epoch id: 64, Training steps: 1250, Loss: 0.530989
Epoch id: 65, Training steps: 250, Loss: 0.870318
Epoch id: 65, Training steps: 500, Loss: 0.532918
Epoch id: 65, Training steps: 750, Loss: 0.525669
Epoch id: 65, Training steps: 1000, Loss: 0.526208
Epoch id: 65, Training steps: 1250, Loss: 0.511765
Epoch id: 66, Training steps: 250, Loss: 0.876393
Epoch id: 66, Training steps: 500, Loss: 0.524659
Epoch id: 66, Training steps: 750, Loss: 0.535485
Epoch id: 66, Training steps: 1000, Loss: 0.519221
Epoch id: 66, Training steps: 1250, Loss: 0.515853
Epoch id: 67, Training steps: 250, Loss: 0.869631
Epoch id: 67, Training steps: 500, Loss: 0.516448
Epoch id: 67, Training steps: 750, Loss: 0.525497
Epoch id: 67, Training steps: 1000, Loss: 0.515436
Epoch id: 67, Training steps: 1250, Loss: 0.513309
Epoch id: 68, Training steps: 250, Loss: 0.888701
Epoch id: 68, Training steps: 500, Loss: 0.516979
Epoch id: 68, Training steps: 750, Loss: 0.513445
Epoch id: 68, Training steps: 1000, Loss: 0.521600
Epoch id: 68, Training steps: 1250, Loss: 0.530388
Epoch id: 69, Training steps: 250, Loss: 0.871539
Epoch id: 69, Training steps: 500, Loss: 0.522731
Epoch id: 69, Training steps: 750, Loss: 0.521709
Epoch id: 69, Training steps: 1000, Loss: 0.525079
Epoch id: 69, Training steps: 1250, Loss: 0.522163
Epoch id: 70, Training steps: 250, Loss: 0.870016
Epoch id: 70, Training steps: 500, Loss: 0.512288
Epoch id: 70, Training steps: 750, Loss: 0.525249
Epoch id: 70, Training steps: 1000, Loss: 0.523705
Epoch id: 70, Training steps: 1250, Loss: 0.517131
Epoch id: 71, Training steps: 250, Loss: 0.864951
Epoch id: 71, Training steps: 500, Loss: 0.522230
Epoch id: 71, Training steps: 750, Loss: 0.529320
Epoch id: 71, Training steps: 1000, Loss: 0.522981
Epoch id: 71, Training steps: 1250, Loss: 0.527630
Epoch id: 72, Training steps: 250, Loss: 0.855861
Epoch id: 72, Training steps: 500, Loss: 0.511730
Epoch id: 72, Training steps: 750, Loss: 0.511741
Epoch id: 72, Training steps: 1000, Loss: 0.526777
Epoch id: 72, Training steps: 1250, Loss: 0.525161
Epoch id: 73, Training steps: 250, Loss: 0.866001
Epoch id: 73, Training steps: 500, Loss: 0.531000
Epoch id: 73, Training steps: 750, Loss: 0.519248
Epoch id: 73, Training steps: 1000, Loss: 0.520802
Epoch id: 73, Training steps: 1250, Loss: 0.528239
Epoch id: 74, Training steps: 250, Loss: 0.868938
Epoch id: 74, Training steps: 500, Loss: 0.522584
Epoch id: 74, Training steps: 750, Loss: 0.513992
Epoch id: 74, Training steps: 1000, Loss: 0.528104
Epoch id: 74, Training steps: 1250, Loss: 0.518705
Epoch id: 75, Training steps: 250, Loss: 0.852283
Epoch id: 75, Training steps: 500, Loss: 0.506040
Epoch id: 75, Training steps: 750, Loss: 0.521300
Epoch id: 75, Training steps: 1000, Loss: 0.507629
Epoch id: 75, Training steps: 1250, Loss: 0.521603
Epoch id: 76, Training steps: 250, Loss: 0.851218
Epoch id: 76, Training steps: 500, Loss: 0.517071
Epoch id: 76, Training steps: 750, Loss: 0.521106
Epoch id: 76, Training steps: 1000, Loss: 0.510156
Epoch id: 76, Training steps: 1250, Loss: 0.511553
Epoch id: 77, Training steps: 250, Loss: 0.863032
Epoch id: 77, Training steps: 500, Loss: 0.512871
Epoch id: 77, Training steps: 750, Loss: 0.512516
Epoch id: 77, Training steps: 1000, Loss: 0.524016
Epoch id: 77, Training steps: 1250, Loss: 0.515780
Epoch id: 78, Training steps: 250, Loss: 0.864452
Epoch id: 78, Training steps: 500, Loss: 0.525178
Epoch id: 78, Training steps: 750, Loss: 0.514935
Epoch id: 78, Training steps: 1000, Loss: 0.528709
Epoch id: 78, Training steps: 1250, Loss: 0.508298
Epoch id: 79, Training steps: 250, Loss: 0.860745
Epoch id: 79, Training steps: 500, Loss: 0.518650
Epoch id: 79, Training steps: 750, Loss: 0.514977
Epoch id: 79, Training steps: 1000, Loss: 0.507981
Epoch id: 79, Training steps: 1250, Loss: 0.532152
Epoch id: 80, Training steps: 250, Loss: 0.874501
Epoch id: 80, Training steps: 500, Loss: 0.494744
Epoch id: 80, Training steps: 750, Loss: 0.512975
Epoch id: 80, Training steps: 1000, Loss: 0.521065
Epoch id: 80, Training steps: 1250, Loss: 0.511096
Traceback (most recent call last):
  File "train.py", line 324, in <module>
    main()
  File "train.py", line 321, in main
    train_kfold(args)
  File "train.py", line 281, in train_kfold
    loss = model.get_loss(feats, device_batch, epoch)
  File "/work/ssd.user/lxk/event_extraction/event_extraction_codes/models/cascade_model.py", line 169, in get_loss
    gold_mask[negative_rand_sample_array[0:negative_samples_max_num]] = torch.ones(negative_samples_max_num).to(self.device)
RuntimeError: shape mismatch: value tensor of shape [60] cannot be broadcast to indexing result of shape [56]
